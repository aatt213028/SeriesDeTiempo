#Prueba binomial

#Prueba de una muestra. H0: p=0.5 vs. Ha: p<>0.5

binom.test(37, 58, p = 0.5,alternative =c("two.sided"),conf.level = 0.95) #c("two.sided", "less", "greater") correct=FALSE

#Exact binomial test

#data:  37 and 58
#number of successes = 37, number of trials = 58, p-value = 0.04794
#alternative hypothesis: true probability of success is not equal to 0.5 Entonces se rechaza la Ho
#95 percent confidence interval:
#  0.5011790 0.7600792
#sample estimates:
#  probability of success 
#0.637931 

##########################################################################
x<-rnorm(100,2,3) #100 datos, conmedia 2 y desviacion estandar 3
x
boxplot(x)
t.test(x,mu=2,alternative=c("two.sided"),conf.level=0.95)

#One Sample t-test

#data:  x
#t = -0.70881, df = 99, p-value = 0.4801 Entonces no rechazo la Ho
#alternative hypothesis: true mean is not equal to 2
#95 percent confidence interval:
#  1.158633 2.398469
#sample estimates:
#  mean of x 
#1.778551

norm.test<-function (x, mu, desviacion.estandar,
alternativa = c("dos.colas", "menor", "mayor"), sd = desviacion.estandar){
if (missing(desviacion.estandar) && missing(sd))
stop("Se debe especificar la desviación estándar de la población")

alternativa <- match.arg(alternativa)
n <- length(x)
z <- (mean(x) - mu)/(sd/sqrt(n))
p.value <- switch(alternativa, dos.colas= 2 * pnorm(abs(z),lower.tail = FALSE), menor = pnorm(z), mayor = 1 - pnorm(z))
return(list(z=z,p.value=p.value))
}


norm.test(x,2,3,alternativa="dos.colas")

#$z
#[1] -0.7381637

#$p.value
#[1] 0.460415 Entonces no rechazo la Ho



#####################################################################################

wilcox.test(x,mu=2,alternative=c("two.sided"),conf.level=0.95)

#Wilcoxon signed rank test with continuity correction, valido bajo xx pequeñas

#data:  x
#V = 2235, p-value = 0.3195 Entonces no se rechaza la Ho
#alternative hypothesis: true location is not equal to 2

mean(x)
#[1] 1.778551

median(x)
#[1] 1.845685
#son similares la media con la mediana
#######################################################################################


smokers  <- c( 83, 90, 129, 70 )
patients <- c( 86, 93, 136, 82 )
boxplot(smokers,patients)
prop.test(smokers, patients)

#4-sample test for equality of proportions without continuity correction

#data:  smokers out of patients
#X-squared = 12.6, df = 3, p-value = 0.005585 Entonces se rechaza la Ho
#alternative hypothesis: two.sided
#sample estimates:
#  prop 1    prop 2    prop 3    prop 4 
#0.9651163 0.9677419 0.9485294 0.8536585 
#######################################################################################################

x1<-rnorm(100)
x2<-rnorm(100,1,1)

boxplot(x1,x2)

plot(density(x1),xlab="",ylab="",col="blue")

par(new=T) #añadir gráfica
plot(density(x2),xlab="",ylab="",col="red")

#Mas mejor

library(lattice)
pob<-factor(c(rep(1,100),rep(2,100))) #crear factores, repetir 1 100 veces en un vector y en ese mismo vector repetir 2 100 veces
x3<-c(x1,x2)
pob

datos<-data.frame(x3,pob)
datos

densityplot(~x3, data=datos,groups=pob,plot.points=TRUE,ref=FALSE)

t.test(x1,x2,alternative=c("two.sided"),conf.level=0.95) #paired=T muestras pareadas
#Welch Two Sample t-test
#data:  x1 and x2
#t = -7.8269, df = 196.16, p-value = 3.044e-13 Entonces rechazo Ho
#alternative hypothesis: true difference in means is not equal to 0
#95 percent confidence interval:
#  -1.4045336 -0.8391877
#sample estimates:
#  mean of x   mean of y 
#-0.07323729  1.04862336


#########################################################################################################
### Probar supuestos para la prueba anterior. Poblaciones normales e igualdad de varianzas

shapiro.test(x1)
#Shapiro-Wilk normality test
#data:  x1
#W = 0.99294, p-value = 0.8842 Entonces no rechazo Ho

shapiro.test(x2)
#Shapiro-Wilk normality test
#data:  x2
#W = 0.98007, p-value = 0.1346 Entonces no rechazo Ho

var.test(x1,x2,alternative=c("two.sided"),conf.level=0.95)
#F test to compare two variances
#data:  x1 and x2
#F = 0.82335, num df = 99, denom df = 99, p-value = 0.3351 Entonces no rechazo Ho
#alternative hypothesis: true ratio of variances is not equal to 1
#95 percent confidence interval:
#  0.5539809 1.2236833
#sample estimates:
#  ratio of variances 
#0.8233451

#########################################################################################################
### Alternativa no paramétrica

wilcox.test(x1,x2,alternative=c("two.sided"),conf.level=0.95)
#Wilcoxon rank sum test with continuity correction
#data:  x1 and x2
#W = 2100, p-value = 1.394e-12 Entonces rechazo Ho
#alternative hypothesis: true location shift is not equal to 0


##########################################################################################################
### Prueba de independencia

x <- matrix(c(12, 5, 7, 7), ncol = 2, nrow=2)
chtest<-chisq.test(x,correct = TRUE) #correct=TRUE es el dafault
chtest$p.value
#[1] 0.4233054
chisq.test(x,simulate.p.value=TRUE,B=10000)$p.value
#[1] 0.2914709
chtest$observed
#      [,1] [,2]
#[1,]   12    7
#[2,]    5    7
chtest$expected
#       [,1]     [,2]
#[1,] 10.419355 8.580645
#[2,]  6.580645 5.419355
chtest$residuals
#       [,1]       [,2]
#[1,]  0.4896818 -0.5396031
#[2,] -0.6161694  0.6789856
x
#      [,1] [,2]
#[1,]   12    7
#[2,]    5    7
#Entonces no rechazo Ho

### Es recomendable usar la Ji-cuadrada???
###########################################################################################

#Ji-cuadrada de bondad de ajuste (homogeneidad)
# Simulacion de un dado honesto

dados= sample(1:6,200,p=c(1,1,1,1,1,1)/6,replace=T)
dd<-table(dados)

### Prueba de bondad de ajuste (homogeneidad)

chisq.test(dd,p=c(1,1,1,1,1,1)/6)
chisq.test(x, p=p, simulate.p.value = TRUE, B = 10000)$p.value

#############################################################################
### Prueba exacta de Fisher

x <- matrix(c(12, 5, 7, 7), ncol = 2)
fisher.test(x)
fisher.test(x)$p.value
fisher.test(x, simulate.p.value=TRUE, B=10000)

##############################################################################
### Correlacion

x <- c(44.4, 45.9, 41.9, 53.3, 44.7, 44.1, 50.7, 45.2, 60.1)
y <- c( 2.6,  3.1,  2.5,  5.0,  3.6,  4.0,  5.2,  2.8,  3.8)

cor.test(x, y,alternative = c("two.sided"),method = c("pearson"), conf.level = 0.95)


cor.test(x, y,alternative = c("two.sided"),method = c("spearman"),
         exact = FALSE, conf.level = 0.95) #Intervalo de confianza solo para la alternativa pearson
         
cor.test(x, y,alternative = c("two.sided"),method = c("spearman"),
         exact = TRUE, conf.level = 0.95)
         
##############################################################################
#### Igualdad de varianza para 3 poblaciones
library(pgirmess)

x<-cbind(rnorm(50),rnorm(50,1,1),rnorm(50,2,1))
grupo<-factor(c(rep(0,50),rep(1,50),rep(2,50)))

boxplot(x[,1],x[,2],x[,3])

library(lattice)

x1<-c(x[,1],x[,2],x[,3])

datos1<-data.frame(x1,grupo)

densityplot(~x1, data=datos1,groups=grupo,plot.points=TRUE)

library(stats)

bartlett.test(x1,grupo)

bartlett.test(x1~grupo,data=datos1)

library(car)

levene.test(x1,grupo)

levene.test(x1~grupo, data=datos1)

fligner.test(x1,grupo) #Prueba no parametrica por rangos

fligner.test(x1,grupo,data=datos1)

friedman.test(x,grupo) 

friedmanmc(x,grupo) 

##############################################################################



resp<-c(0.44,0.44,0.54,0.32,0.21,0.28,0.7,0.77,0.48,0.64,0.71,0.75,0.8,0.76,0.34,0.80,0.73,0.8)
categ<-as.factor(rep(c("A","B","C"),each=6))

kruskal.test(resp,categ)

kruskalmc(resp, categ)

#kruskalmc(resp, categ, prob=0.02)# pa' controlar el nivel de sig. de las pruebas individuales


x <- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
y <- c(3.8, 2.7, 4.0, 2.4)      # with obstructive airway disease
z <- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis
fac<-factor(c(rep(1,5),rep(2,4),rep(3,5)))
kruskal.test(c(x, y, z),fac)


#############################################################################################
x<-c(rnorm(50),rnorm(50,1,1),rnorm(50,2,1))
grupo<-factor(c(rep(0,50),rep(1,50),rep(2,50)))

boxplot(x~grupo)

summary(ajuste<-aov(x~grupo))

TukeyHSD(ajuste, "grupo", ordered = TRUE)
plot(TukeyHSD(ajuste, "grupo"),col=c("red","blue","green")) #También se puede guardar como un objeto y usar plot(nombre objeto)

##################################################################################################

#Todas las distribuciones tienen media?

pmovil<-function(x){
n<-length(x)
ret<-rep(0,n)
for (k in 1:n){ret[k]<-mean(x[1:k])}
return(ret)
}
x<-rnorm(10000)
#x<-rcauchy(10000)
plot(pmovil(x),type="l")
abline(h=0)

########################################################################################################

#Rumbo a bondad de ajuste

x<-rnorm(500)

par(mfrow=c(1,2))

plot(density(x),col="blue")

curve(dnorm(x),from=-3,to=3,add=T,col="green")

plot(ecdf(x),lty=1)

curve(pnorm(x),from=-3,to=3,add=T,col="violet")

#Exploracion grafica

qqnorm(x)
qqline(x, col="violet")

y<-rt(100,9)
plot(qt(ppoints(y),9),sort(y))
abline(c(0,1),col="blue")

z<-rexp(100)
plot(qexp(ppoints(z),1),sort(z))
abline(c(0,1),col="green")


hist(x,prob=T)

lines(density(x),col="green")


#Pruebas formales para normalidad

library(nortest)

c(shapiro.test(x),ks.test(x,"pnorm",m=0,sd=1), sf.test(x), ad.test(x),cvm.test(x),lillie.test(x),pearson.test(x))

library(ADGofTest)
x<-rweibull(100,2,3)
ad.test(x,pweibull,2,3)

p<-rpois(100,3)
ad.test(p,ppois,3)


#Estimacion de los parametros de una distribucion

library(MASS)

x<-rnorm(100,10,4)

fitdistr(x, "normal")

w<-rweibull(100,3,10)

fitdistr(w,"Weibull")

e<-rexp(3)

fitdistr(e,"exponential")

################## El teorema central del límite dinámico

library(TeachingDemos)
library(tcltk)
vis.binom()

############Explorando la verosimilitud

mle.demo()
